{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your name:Sam Duran\n",
    "\n",
    "Your Andrew ID:sduran\n",
    "\n",
    "Collaborators (if none, say \\\"none\\\"; do *not* leave this blank):none"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Email spam classification [45 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   - Get the data from: http://www.andrew.cmu.edu/user/georgech/preprocessed-enron-email-dataset.zip\n",
    "   - Unzip this into the same folder as this notebook, rename it to `email-data`\n",
    "   - The folder contains 3 subfolders:\n",
    "      - `ham` contains ham emails.\n",
    "      - `spam` contains spam emails.\n",
    "      - `testing` is a folder containing test emails for your classifier. The ham/spam label is in the filename.\n",
    "      \n",
    "**Important**: For this problem, do *not* use neural nets/deep nets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) Print the number of ham and spam emails [1 point]\n",
    " \n",
    "In addition to providing the code, respond to the following questions:\n",
    "\n",
    "   - Is this dataset imbalanced? Will this be problematic in training the model?\n",
    "   - If so, how would you address it? (You do *not* have to implement what you suggest here for later parts of the problem.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count of emails in: ./email-data\\ham\n",
      "1500\n",
      "count of emails in: ./email-data\\spam\n",
      "3671\n",
      "count of emails in: ./email-data\\testing\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def email_count(directory):\n",
    "    doc_list = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith('.txt'):\n",
    "            doc_list.append(filename)\n",
    "    return len(doc_list)\n",
    "\n",
    "dir_list = [x[0] for x in os.walk('./email-data')][1:]   \n",
    "\n",
    "for i in dir_list:\n",
    "    print(\"count of emails in: \" + i)\n",
    "    print(email_count(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The data is imbalanced as there are more spam emails than ham emails. This can cause problems in classification problems \n",
    "# as many ML algorithms might just view the minority class as noise and mostly predict the majority class. I can resolve this\n",
    "# by oversampling the minority class and ensuring that the data is more balanced when training.   \n",
    "# Also, I might see what seems like a high accuracy number, but that simply reflects the distribution of the data\n",
    "# one way to combat this is ensure that I am always comparing my results to a baseline that reflects the \n",
    "# distribution of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Construct the documents [4 points]\n",
    " \n",
    "   - Provided below is a function that returns a document present in a file given a fileName.\n",
    "   - The function performs some preprocessing to (1) remove punctuation, (2),(3) remove whitespace and (4) lowercase all words.\n",
    "   - Use this function to construct a list of documents.\n",
    "   - Also construct a list of document labels containing `1` for spam and `0` for ham."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import codecs\n",
    "\n",
    "def makeWordList(path):\n",
    "    \n",
    "    with codecs.open(path, \"r\", encoding='utf-8', errors='ignore') as f:\n",
    "        corpus_text = f.read()\n",
    "\n",
    "    for c in string.punctuation:\n",
    "        corpus_text = corpus_text.replace(c, \"\")  # -- (1)\n",
    "    \n",
    "    text = re.sub(r'\\S*\\d\\S*','',corpus_text) # -- (2)\n",
    "    text = re.sub(r'[^\\w\\s]','',text)         # -- (3)\n",
    "    \n",
    "    text = text.lower().split()           # -- (4)         \n",
    "    \n",
    "    li = []\n",
    "    for token in text:\n",
    "        li.append(token)\n",
    "\n",
    "    return \" \".join(li)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "labels = []\n",
    "for (root,dirs,files) in os.walk('./email-data'):\n",
    "    for file in files:\n",
    "        if root == './email-data\\ham':\n",
    "            data.append([makeWordList(os.path.join(root,file))])\n",
    "            labels.append(1)\n",
    "        if root == './email-data\\spam':\n",
    "            data.append([makeWordList(os.path.join(root,file))])\n",
    "            labels.append(0)\n",
    "\n",
    "final = []\n",
    "for i in data:\n",
    "    final.append(i[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c) Construct the document matrix `X` as a matrix of word frequencies [5 points]\n",
    "\n",
    "   - Use the `CountVectorizer` from scikit-learn.\n",
    "   - Set `min_df=50`; this drops words that don't occur in at least 50 documents.\n",
    "   - Set `stop_words=\"english\"` and `max_df=0.8` to filter out stop-words.\n",
    "   - Print the size of the vocabulary (number of unique words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of vocab\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1680"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "tf_vectorizer = CountVectorizer(max_df=0.8,\n",
    "                                min_df=50,\n",
    "                                stop_words='english')\n",
    "tf = tf_vectorizer.fit_transform(final)\n",
    "\n",
    "print('size of vocab')\n",
    "tf.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (d) k-NN and random forest: Hyperparameter selection [15 points]\n",
    "\n",
    "Now that you have your documents and labels as training data, you can perform 5-fold cross-validation to select the hyperparameters for different learning algorithms.\n",
    "\n",
    "The hyperparameter with the best performance averaged across 5 folds is chosen. Use the **weighted F1-score** as the evaluation metric (i.e., for the `f1_score` function imported from `sklearn.metrics`, be sure to use the parameter `average='weighted'`).\n",
    "\n",
    "   - k-NN: Select `k` from a range of values of your choice.\n",
    "   - Random forest: Select `max_features` **and** `min_samples_leaf` from a grid of your choice.\n",
    "\n",
    "Store each chosen hyperparameter as `best_k`, `best_C`, `best_max_features`, and `best_min_samples_leaf` respectively.\n",
    "\n",
    "Provided is some seed code for cross-validation that you may modify and reuse. Do not use the cross-validations score or grid-search functions from scikit-learn (you may use `KFold`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameter setting (k-fold): 3\n",
      "Best hyperparameter setting (random forest): (41, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "num_folds = 5\n",
    "k_fold = KFold(num_folds,shuffle=True)\n",
    "hyperparameter_settings = [2,3,4,5,6,7,8]  # fill this with hyperparameter settings that you want to try\n",
    "\n",
    "best_hyperparam_setting = None\n",
    "best_cross_val_score = -np.inf  # assumes that a higher score is better\n",
    "for hyperparam_setting in hyperparameter_settings:\n",
    "    fold_scores = []\n",
    "    for proper_train_indices, val_indices in k_fold.split(tf):\n",
    "        proper_train_features = tf[proper_train_indices]\n",
    "        proper_train_labels = np.array(labels)[proper_train_indices]\n",
    "        val_features = tf[val_indices]\n",
    "        val_labels = np.array(labels)[val_indices]\n",
    "        \n",
    "        knn = KNeighborsClassifier(n_neighbors=hyperparam_setting)\n",
    "        knn.fit(proper_train_features,proper_train_labels)\n",
    "        pred = knn.predict(val_features)\n",
    "        score = f1_score(pred, val_labels)\n",
    "        fold_scores.append(score)\n",
    "    cross_val_score = np.mean(fold_scores)\n",
    "    if cross_val_score > best_cross_val_score:  # assumes that a higher score is better\n",
    "        best_cross_val_score = cross_val_score\n",
    "        best_hyperparam_setting = hyperparam_setting\n",
    "\n",
    "best_k = best_hyperparam_setting\n",
    "\n",
    "print('Best hyperparameter setting (k-fold):', best_hyperparam_setting)\n",
    "\n",
    "num_features = tf.shape[1]\n",
    "\n",
    "hyperparameter_settings = [(max_features, min_samples_leaf)\n",
    "                           for max_features in [int(np.ceil(np.sqrt(num_features) / 4)),\n",
    "                                                int(np.ceil(np.sqrt(num_features))),\n",
    "                                                int(np.ceil(np.sqrt(num_features) * 4))]\n",
    "                           for min_samples_leaf in [1, 2, 4, 8, 16]]  \n",
    "\n",
    "\n",
    "for hyperparameter_setting in hyperparameter_settings:\n",
    "    max_features, min_samples_leaf = hyperparameter_setting\n",
    "    fold_scores = []\n",
    "    for proper_train_indices, val_indices in k_fold.split(tf):\n",
    "        proper_train_features = tf[proper_train_indices]\n",
    "        proper_train_labels = np.array(labels)[proper_train_indices]\n",
    "        val_features = tf[val_indices]\n",
    "        val_labels = np.array(labels)[val_indices]\n",
    "        \n",
    "        classifier = RandomForestClassifier(max_features=max_features,\n",
    "                                            min_samples_leaf=min_samples_leaf)\n",
    "        \n",
    "        classifier.fit(proper_train_features, proper_train_labels)\n",
    "        pred = classifier.predict(val_features)\n",
    "        score = f1_score(pred, val_labels)\n",
    "        fold_scores.append(score)\n",
    "    cross_val_score = np.mean(fold_scores)\n",
    "    if cross_val_score > best_cross_val_score:  # assumes that a higher score is better\n",
    "        best_cross_val_score = cross_val_score\n",
    "        best_hyperparam_setting = (max_features, min_samples_leaf)\n",
    "        \n",
    "best_max_features = best_hyperparam_setting[0]\n",
    "best_min_samples_leaf = best_hyperparam_setting[1]\n",
    "        \n",
    "print('Best hyperparameter setting (random forest):', best_hyperparam_setting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (e) Classifier testing: Precision-Recall and ROC curves [20 points]\n",
    "\n",
    "   - Use the best hyperparameters for each classifier from the previous question to **train** your classifiers on the training data.\n",
    "   - Use test emails to in the `testing` folder to **test** your classifiers and construct the plots below.\n",
    "\n",
    "Things to plot:\n",
    "\n",
    "   - Construct one plot containing 2 ROC curves, one for each classifier.\n",
    "   - In the legend of this plot, display the AUC for each classifier.\n",
    "   - Construct one plot containing 2 precision-recall curves, one for each classifier.\n",
    "   - In the legend of each plot, display the average precision for each classifier.\n",
    "\n",
    "Note that these plots are on the test data: you will have to read in this data, construct a document matrix and labels. Some words in the test data may not have been present in the training data: there are multiple ways to address this, briefly describe your approach.\n",
    "\n",
    "Things to answer:\n",
    "\n",
    "   - Of the ROC and Precision-Recall curves, which one would you use for this task and why?\n",
    "   - Which classifier is the best, according to your chosen curves?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "test_mask = []\n",
    "train_mask = []\n",
    "for (root,dirs,files) in os.walk('./email-data'):\n",
    "    for file in files:\n",
    "        train_mask.append(root in ['./email-data\\spam','./email-data\\ham'])\n",
    "        test_mask.append(root not in ['./email-data\\spam','./email-data\\ham'])\n",
    "        if file[-8:] == 'spam.txt':\n",
    "            data.append([makeWordList(os.path.join(root,file))])\n",
    "            labels.append(0)\n",
    "        else:\n",
    "            data.append([makeWordList(os.path.join(root,file))])\n",
    "            labels.append(1)\n",
    "\n",
    "final = []\n",
    "for i in data:\n",
    "    final.append(i[0])\n",
    "\n",
    "tf_vectorizer = CountVectorizer(max_df=0.8,\n",
    "                                min_df=50,\n",
    "                                stop_words='english')\n",
    "\n",
    "tf = tf_vectorizer_test.fit_transform(final)\n",
    "tf = tf.todense()\n",
    "\n",
    "tf_train = tf[train_mask]\n",
    "tf_test = tf[test_mask]\n",
    "\n",
    "label_train = np.array(labels)[train_mask]\n",
    "label_test = np.array(labels)[test_mask]\n",
    "\n",
    "classifier = RandomForestClassifier(max_features=41,min_samples_leaf=1)\n",
    "classifier.fit(tf_train, label_train)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(tf_train,label_train)\n",
    "\n",
    "\n",
    "y_score = classifier.predict_proba(tf_test)[:,1]\n",
    "fpr, tpr, thresholds = roc_curve(label_test, y_score, pos_label=1)\n",
    "auc = np.trapz(tpr, fpr)\n",
    "plt.plot(fpr, tpr, linestyle='-', alpha=0.5, label = 'Random Forest, AUC = ' + str(np.round(auc,2)))\n",
    "\n",
    "y_score = knn.predict_proba(tf_test)[:,1]\n",
    "fpr, tpr, thresholds = roc_curve(label_test, y_score, pos_label=1)\n",
    "auc = np.trapz(tpr, fpr)\n",
    "plt.plot(fpr, tpr, linestyle='-', alpha=0.5, label = 'KNN, AUC = ' + str(np.round(auc,2)))\n",
    "\n",
    "\n",
    "plt.title(\"ROC curve\")\n",
    "plt.legend(loc = \"best\")\n",
    "plt.xlabel(\"FPR\")\n",
    "plt.ylabel(\"TPR\")\n",
    "plt.grid()\n",
    "plt.show() \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To deal with mismatch in number of features. I created a new tf_vectorizor object with both train and test data, then used a mask to split train and test data up.   \n",
    "\n",
    "Random Forest seems to dominate KNN on ROC curve, would choose this approach over KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Questionnaire [5 points]\n",
    "\n",
    "Please answer this questionnaire: https://forms.gle/2DEGoF5vRSo8hfQ96"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
